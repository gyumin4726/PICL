# PICL: ë¬¼ë¦¬ ì •ë³´ ê¸°ë°˜ ì—°ì† í•™ìŠµì„ í†µí•œ ê´‘í•™ ì—­ë¬¸ì œ í•´ê²°

## ğŸ¯ ì—°êµ¬ ê°œìš”

ì´ ì €ì¥ì†ŒëŠ” **ë¬¼ë¦¬ ì •ë³´ ê¸°ë°˜ ì—°ì† í•™ìŠµ(Physics-Informed Continual Learning, PICL)** í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬í˜„í•˜ì—¬, **VMamba**ì™€ **1D Mamba** ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•´ ì‹œê°„ ê²Œì´íŠ¸ ê´‘í•™ ì‚°ë€ ì´ë¯¸ì§€ë¡œë¶€í„° ì¬ë£Œì˜ **3ê°€ì§€ ë¬¼ë¦¬ê³„ìˆ˜**ë¥¼ ì—­ì¶”ì •í•˜ëŠ” ê´‘í•™ ì—­ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

### í•µì‹¬ ëª©í‘œ
- **ì…ë ¥**: 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ê´‘í•™ ì‚°ë€ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤
- **ì¶œë ¥**: 4ê°€ì§€ ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡
  1. êµ´ì ˆë¥  (n)
  2. í¡ìˆ˜ ê³„ìˆ˜ (Î¼a)
  3. ì‚°ë€ ê³„ìˆ˜ (Î¼s)
  4. ë¹„ë“±ë°©ì„± ì¸ì (g)
  - ìœ ë„ ê³„ìˆ˜: Î¼s' = Î¼s Ã— (1 - g) (ë“±ë°© í™˜ì‚° ì‚°ë€ ê³„ìˆ˜)
- **ë°©ë²•**: ë¬¼ë¦¬ ì •ë³´ ê¸°ë°˜ ì‹ ê²½ë§ (PINN) - ë°ì´í„° ì†ì‹¤ + ë¬¼ë¦¬ ì†ì‹¤

### ì£¼ìš” í˜ì‹ 
1. **ì´ì¤‘ ê²½ë¡œ ì•„í‚¤í…ì²˜**: ì‹ ê²½ë§ ì˜ˆì¸¡ ê²½ë¡œì™€ ë¬¼ë¦¬ëŸ‰ ê³„ì‚° ê²½ë¡œì˜ ë³‘ë ¬ ì²˜ë¦¬
2. **ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ í†µí•©**: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ë§Œì¡±í•˜ëŠ”ì§€ ìë™ ê²€ì¦
3. **íš¨ìœ¨ì ì¸ ì‹œí€€ìŠ¤ ëª¨ë¸ë§**: 1D Mambaë¥¼ ì‚¬ìš©í•œ ì‹œê°„ì  ì˜ì¡´ì„± ì²˜ë¦¬
   - Spatial Projectionìœ¼ë¡œ ê³µê°„ ì •ë³´ í†µí•© í›„ ì‹œê°„ ëª¨ë¸ë§
   - ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… í™œìš©ìœ¼ë¡œ ì‹œê°„ ë™ì—­í•™ ë³´ì¡´
4. **FT-Transformer ê¸°ë°˜ íšŒê·€**: Feature Tokenizer + Transformerë¡œ ë¬¼ë¦¬ ê³„ìˆ˜ ê°„ ìƒê´€ê´€ê³„ í•™ìŠµ
   - Single headë¡œ 4ê°œ ê³„ìˆ˜ ë™ì‹œ ì˜ˆì¸¡
   - Self-attentionìœ¼ë¡œ ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ ëª¨ë¸ë§

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

### ì™„ì „í•œ PICL íŒŒì´í”„ë¼ì¸ (ì´ì¤‘ ê²½ë¡œ êµ¬ì¡°)

PICL ëª¨ë¸ì€ **ë™ì‹œì— ì‹¤í–‰ë˜ëŠ” ë‘ ê°œì˜ ë…ë¦½ì ì¸ ê²½ë¡œ**ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

```
ì…ë ¥: 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ (B, 5, 3, 224, 224)
â”‚
â”œâ”€ PATH 1: ì‹ ê²½ë§ ì˜ˆì¸¡ ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   â”‚                                              â”‚
â”‚   â”œâ”€ 2D VMamba (ê³µê°„ íŠ¹ì§• ì¶”ì¶œ)                 â”‚
â”‚   â”‚   (B, 5, 3, 224, 224) â†’ (B*5, 1024, 7, 7) â”‚
â”‚   â”‚                                              â”‚
â”‚   â”œâ”€ Spatial Flatten + Projection (ê³µê°„ í†µí•©)  â”‚
â”‚   â”‚   (B, 5, 1024, 7, 7) â†’ (B, 5, 1024)        â”‚
â”‚   â”‚                                              â”‚
â”‚   â”œâ”€ 1D Mamba (ì‹œê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ë§)              â”‚
â”‚   â”‚   (B, 5, 1024) â†’ (B, 5, 1024)              â”‚
â”‚   â”‚   ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì„ íƒ â†’ (B, 1024)          â”‚
â”‚   â”‚                                              â”‚
â”‚   â””â”€ FT-Transformer (ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡)             â”‚
â”‚       (B, 1024) â†’ (B, 4)                         â”‚
â”‚       ì¶œë ¥: n_pred, Î¼a_pred, Î¼s_pred, g_pred   â”‚
â”‚                                                 â”‚
â””â”€ PATH 2: ë¬¼ë¦¬ëŸ‰ ê³„ì‚° ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                              â”‚
    â”œâ”€ ì›ë³¸ ì´ë¯¸ì§€ ì§ì ‘ ì‚¬ìš© (grayscale ë³€í™˜)     â”‚
    â”‚   (B, 5, 3, 224, 224) â†’ (B, 5, 224, 224)    â”‚
    â”‚                                              â”‚
    â”œâ”€ ë¬¼ë¦¬ëŸ‰ ê³„ì‚°                                â”‚
    â”‚   - Î¦(r,t): ì›ë³¸ ì´ë¯¸ì§€ í”½ì…€ê°’              â”‚
    â”‚   - âˆ‚Î¦/âˆ‚t: ì‹œê°„ ë¯¸ë¶„ (ìœ í•œ ì°¨ë¶„ë²•)          â”‚
    â”‚   - âˆ‡Â²Î¦: ê³µê°„ ë¼í”Œë¼ì‹œì•ˆ (ìœ í•œ ì°¨ë¶„ë²•)      â”‚
    â”‚                                              â”‚
    â””â”€ ì¶œë ¥: ë¬¼ë¦¬ëŸ‰ (Î¦, âˆ‚Î¦/âˆ‚t, âˆ‡Â²Î¦)              â”‚
                                                 â”‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
              ìµœì¢… ê²°í•©: PINN ì†ì‹¤ ê³„ì‚°
                      â†“
    PDE ë°©ì •ì‹: n/c * âˆ‚Î¦/âˆ‚t + Î¼a*Î¦ - âˆ‡Â·(Dâˆ‡Î¦) = 0
                      â†“
    Residual = (ì˜ˆì¸¡ê°’ + ê³„ì‚°ê°’) â†’ 0ì— ê°€ê¹Œì›Œì•¼ í•¨
                      â†“
    Loss = Classification Loss + Data Loss + Physics Loss
```

### PATH 1: ì‹ ê²½ë§ ì˜ˆì¸¡ ê²½ë¡œ (Neural Network Prediction)

#### 1. **2D VMamba ë°±ë³¸** (ê³µê°„ íŠ¹ì§• ì¶”ì¶œê¸°)
- **ì…ë ¥**: `(B, 5, 3, 224, 224)` - 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ (0-1ns, 1-2ns, 2-3ns, 3-4ns, 4-5ns)
- **ì²˜ë¦¬**: 
  - ì´ë¯¸ì§€ë¥¼ `(B*5, 3, 224, 224)`ë¡œ í‰íƒ„í™”í•˜ì—¬ VMambaì— ì…ë ¥
  - VMamba ë°±ë³¸ì´ ê° ì´ë¯¸ì§€ì—ì„œ ê³µê°„ íŠ¹ì§• ì¶”ì¶œ
  - **ê³µê°„ ì°¨ì› ë³´ì¡´**: `(B*5, 1024, H', W')` í˜•íƒœë¡œ ì¶œë ¥
- **êµ¬í˜„**: `vmamba_backbone.py`ì˜ `VMambaBackbone` í´ë˜ìŠ¤

#### 2. **Spatial Flatten + Projection** (ê³µê°„ ì •ë³´ í†µí•©)
- **ì…ë ¥**: `(B, 5, 1024, 7, 7)` - ì‹œê°„ë³„ë¡œ ì¬êµ¬ì„±ëœ ê³µê°„ íŠ¹ì§•ë§µ
- **ì²˜ë¦¬**: 
  - ê° íƒ€ì„ìŠ¤í…ì˜ 7Ã—7 ê³µê°„ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ í‰íƒ„í™” â†’ `(B, 5, 50176)`
  - í•™ìŠµ ê°€ëŠ¥í•œ projection ë„¤íŠ¸ì›Œí¬ë¡œ ì°¨ì› ì¶•ì†Œ â†’ `(B, 5, 1024)`
  - ê³µê°„ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ íš¨ìœ¨ì ì¸ í‘œí˜„ í•™ìŠµ
- **ì¶œë ¥**: `(B, 5, 1024)` - ê³µê°„ ì •ë³´ê°€ í†µí•©ëœ ì‹œê³„ì—´ íŠ¹ì§•
- **ì¥ì **: ê³µê°„ ìƒê´€ê´€ê³„ë¥¼ ìœ ì§€í•˜ë©´ì„œ 1D Mambaì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜

#### 3. **1D Mamba** (ì‹œê°„ ì‹œí€€ìŠ¤ ëª¨ë¸ëŸ¬)
- **ì…ë ¥**: `(B, 5, 1024)` - 5ê°œ íƒ€ì„ìŠ¤í…ì˜ íŠ¹ì§• ë²¡í„° ì‹œí€€ìŠ¤
- **ì²˜ë¦¬**:
  - 1D Mambaê°€ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì‹œê°„ì  ì˜ì¡´ì„± ëª¨ë¸ë§
  - ê° íƒ€ì„ìŠ¤í…ì´ ì´ì „ íƒ€ì„ìŠ¤í…ì˜ ì •ë³´ë¥¼ ëˆ„ì ì ìœ¼ë¡œ í¬í•¨
  - ì¶œë ¥: `(B, 5, 1024)` - ëª¨ë“  íƒ€ì„ìŠ¤í…ì˜ hidden states
  - **ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì„ íƒ**: `h_5 = output[:, -1, :]`
  - `h_5`ëŠ” ì „ì²´ ì‹œê°„ ì§„í™” ì •ë³´ë¥¼ ëˆ„ì í•œ ìµœì¢… state
- **ì¶œë ¥**: `(B, 1024)` - ì‹œê°„ ì •ë³´ê°€ ëˆ„ì ëœ ìµœì¢… íŠ¹ì§• ë²¡í„°
- **êµ¬í˜„**: `mamba_1d_temporal.py`ì˜ `SequenceToValue` í´ë˜ìŠ¤
- **ì„¤ê³„ ì˜ë„**: í‰ê·  í’€ë§ ëŒ€ì‹  ë§ˆì§€ë§‰ state ì‚¬ìš©ìœ¼ë¡œ ì‹œê°„ ë™ì—­í•™ ë³´ì¡´

#### 4. **ë³‘ë ¬ í—¤ë“œ** (ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡ + ì¬ë£Œ ë¶„ë¥˜)
- **ì…ë ¥**: `(B, 1024)` - ì‹œê°„ì  íŠ¹ì§• ë²¡í„°
- **FT-Transformer Regressor** (ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡):
  - ì•„í‚¤í…ì²˜:
    1. Feature Tokenization: 1024 â†’ 16 tokens Ã— 64 dim
    2. Token Embedding: 64 â†’ 192 dim
    3. [CLS] Token ì¶”ê°€ (ì •ë³´ ì§‘ì•½ìš©)
    4. Transformer Encoder (3 layers, 8 heads)
    5. Single Output Head: [CLS] â†’ 4ê°œ ê³„ìˆ˜ ë™ì‹œ ì˜ˆì¸¡
  - ì¶œë ¥: `(B, 4)` - 4ê°œì˜ ë¬¼ë¦¬ê³„ìˆ˜
    - `n_pred`: êµ´ì ˆë¥  (Refractive Index)
    - `mu_a_pred`: í¡ìˆ˜ ê³„ìˆ˜ (Absorption Coefficient)
    - `mu_s_pred`: ì‚°ë€ ê³„ìˆ˜ (Scattering Coefficient)
    - `g_pred`: ë¹„ë“±ë°©ì„± ì¸ì (Anisotropy Factor)
    - ìœ ë„: `mu_s_prime = mu_s Ã— (1 - g)` (ë“±ë°© í™˜ì‚° ì‚°ë€ ê³„ìˆ˜)
  - êµ¬í˜„: `picl_model.py`ì˜ `FTTransformerRegressor` í´ë˜ìŠ¤
  - **í•µì‹¬**: Single headë¡œ 4ê°œ ê³„ìˆ˜ë¥¼ ë™ì‹œ ì˜ˆì¸¡í•˜ì—¬ ë¬¼ë¦¬ ê³„ìˆ˜ ê°„ ìƒê´€ê´€ê³„ í•™ìŠµ
- **ETF Classifier** (ì¬ë£Œ ë¶„ë¥˜):
  - ì²˜ë¦¬: Equiangular Tight Frame ê¸°ë°˜ ë¶„ë¥˜ê¸°
  - ì¶œë ¥: `(B, 5)` - 5ê°œ ì¬ë£Œì— ëŒ€í•œ ë¡œì§“
  - êµ¬í˜„: `picl_model.py`ì˜ `ETFClassifier` í´ë˜ìŠ¤

### PATH 2: ë¬¼ë¦¬ëŸ‰ ê³„ì‚° ê²½ë¡œ (Physics Quantities Computation)

#### 1. **ì›ë³¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬**
- **ì…ë ¥**: `(B, 5, 3, 224, 224)` - ì›ë³¸ RGB ì´ë¯¸ì§€ ì‹œí€€ìŠ¤
- **ì²˜ë¦¬**: RGBë¥¼ grayscaleë¡œ ë³€í™˜ (í‰ê· ê°’ ì‚¬ìš©)
- **ì¶œë ¥**: `(B, 5, 224, 224)` - í”Œë£¨ì–¸ìŠ¤ìœ¨ `Î¦(r,t)`ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€

#### 2. **ì‹œê°„ ë¯¸ë¶„ ê³„ì‚°** (âˆ‚Î¦/âˆ‚t)
- **ì…ë ¥**: `(B, 5, 224, 224)` - í”Œë£¨ì–¸ìŠ¤ìœ¨ ì‹œí€€ìŠ¤
- **ë°©ë²•**: ìœ í•œ ì°¨ë¶„ë²• (Forward Difference)
  ```python
  âˆ‚Î¦/âˆ‚t â‰ˆ (Î¦(t+1) - Î¦(t)) / Î”t
  ```
- **ì¶œë ¥**: `(B, 4, 224, 224)` - 4ê°œì˜ ì‹œê°„ ê°„ê²©ì— ëŒ€í•œ ë¯¸ë¶„
  - ê°„ê²© 0: t1-t2
  - ê°„ê²© 1: t2-t3
  - ê°„ê²© 2: t3-t4
  - ê°„ê²© 3: t4-t5
- **ë¬¼ë¦¬ ë‹¨ìœ„**: `dt=1e-9 s` (1.0 ns) - MCX ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • ê¸°ì¤€
- **êµ¬í˜„**: `pde_physics.py`ì˜ `compute_time_derivative()` ë©”ì„œë“œ

#### 3. **ê³µê°„ ë¯¸ë¶„ ê³„ì‚°** (âˆ‡Â·(Dâˆ‡Î¦))
- **ì…ë ¥**: `(B, 5, 224, 224)` - í”Œë£¨ì–¸ìŠ¤ìœ¨ ì‹œí€€ìŠ¤
- **ëª¨ë“  ì‹œê°„ ìŠ¤í…**: ê° ì‹œê°„ ìŠ¤í…(t=0, 1, 2, 3)ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°
- **ë°©ë²•**: ìœ í•œ ì°¨ë¶„ë²• (Central Difference)
  ```python
  âˆ‡Î¦ = (âˆ‚Î¦/âˆ‚x, âˆ‚Î¦/âˆ‚y)  # ê¸°ìš¸ê¸°
  Dâˆ‡Î¦ = D Ã— âˆ‡Î¦          # í™•ì‚° ê³„ìˆ˜ ê³±í•˜ê¸°
  âˆ‡Â·(Dâˆ‡Î¦) = âˆ‚(Dâˆ‚Î¦/âˆ‚x)/âˆ‚x + âˆ‚(Dâˆ‚Î¦/âˆ‚y)/âˆ‚y  # ë°œì‚°
  ```
- **ì¶œë ¥**: `(B, 4, 224, 224)` - ê° ì‹œê°„ ìŠ¤í…ì˜ ê³µê°„ ë¯¸ë¶„
- **ë¬¼ë¦¬ ë‹¨ìœ„**: `dx=1e-3 m` (1.0 mm), `dy=1e-3 m` (1.0 mm) - MCX ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • ê¸°ì¤€
- **êµ¬í˜„**: `pde_physics.py`ì˜ `compute_gradient_divergence()` ë©”ì„œë“œ

#### 4. **í™•ì‚° ê³„ìˆ˜ ê³„ì‚°** (D)
- **ì…ë ¥**: ì˜ˆì¸¡ëœ `Î¼a`, `Î¼s'`
- **ê³µì‹**: 
  ```python
  D = 1 / (3 * (Î¼a + Î¼s'))
  ```
- **ì¶œë ¥**: `(B, 1, 1, 1)` - ë°°ì¹˜ë³„ í™•ì‚° ê³„ìˆ˜
- **êµ¬í˜„**: `pde_physics.py`ì˜ `diffusion_coefficient()` ë©”ì„œë“œ

### ìµœì¢… ê²°í•©: PINN ì†ì‹¤ ê³„ì‚° (Physics-Informed Loss)

#### 1. **PDE ì”ì°¨ ê³„ì‚°** (Residual)
- **ë°©ì •ì‹**: 
  ```
  n/c * âˆ‚Î¦/âˆ‚t + Î¼a*Î¦ - âˆ‡Â·(Dâˆ‡Î¦) = S(r,t) â‰ˆ 0
  ```
- **ì…ë ¥**:
  - PATH 1 ê²°ê³¼: `n_pred`, `mu_a_pred`, `mu_s_prime_pred` (ì˜ˆì¸¡ê°’)
  - PATH 2 ê²°ê³¼: `Î¦`, `âˆ‚Î¦/âˆ‚t`, `âˆ‡Â·(Dâˆ‡Î¦)` (ê³„ì‚°ê°’)
- **ê³„ì‚°**:
  ```python
  residual = (n_pred/c) * dphi_dt + mu_a_pred * phi - div_D_grad_phi - source
  ```
- **ì¶œë ¥**: `(B, 4, 224, 224)` - ê° ì‹œê°„ ê°„ê²©ê³¼ ê° í”½ì…€ë§ˆë‹¤ì˜ ì”ì°¨
- **êµ¬í˜„**: `pde_physics.py`ì˜ `pde_residual()` ë©”ì„œë“œ

#### 2. **ë¬¼ë¦¬ ì†ì‹¤** (Physics Loss)
- **ê³„ì‚°**:
  ```python
  physics_loss = HuberLoss(residual, delta=0.1)
  ```
  - Huber Loss ì‚¬ìš©: ì´ìƒì¹˜ì— ê°•ê±´í•˜ë©°, í° ì˜¤ì°¨ì— ëŒ€í•´ ì„ í˜• í˜ë„í‹°
  - `delta=0.1`: ì´ì°¨ ì˜ì—­ê³¼ ì„ í˜• ì˜ì—­ ì‚¬ì´ì˜ ì„ê³„ê°’
  - ëª¨ë“  í”½ì…€ì˜ ì”ì°¨ì— ëŒ€í•´ Huber Loss ê³„ì‚° í›„ í‰ê· 
  - ì´ `B Ã— 4 Ã— 224 Ã— 224` ê°œì˜ ê°’ì— ëŒ€í•´ í‰ê· 
- **ì˜ë¯¸**: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ì–¼ë§ˆë‚˜ ì˜ ë§Œì¡±í•˜ëŠ”ì§€ ì¸¡ì •
  - `physics_loss â‰ˆ 0`: ë¬¼ë¦¬ ë²•ì¹™ì„ ì˜ ë§Œì¡±
  - `physics_loss > 0`: ë¬¼ë¦¬ ë²•ì¹™ ìœ„ë°˜
- **êµ¬í˜„**: `pde_physics.py`ì˜ `physics_loss()` ë©”ì„œë“œ

#### 3. **ë°ì´í„° ì†ì‹¤** (Data Loss)
- **ê³„ì‚°**:
  ```python
  data_loss_n = HuberLoss(n_pred, n_true, delta=0.1)
  data_loss_mu_a = HuberLoss(mu_a_pred, mu_a_true, delta=0.1)
  data_loss_mu_s = HuberLoss(mu_s_pred, mu_s_true, delta=0.1)
  data_loss_g = HuberLoss(g_pred, g_true, delta=0.1)
  data_loss = (data_loss_n + data_loss_mu_a + data_loss_mu_s + data_loss_g) / 4
  ```
- **ì˜ë¯¸**: ì˜ˆì¸¡ëœ 4ê°œ ë¬¼ë¦¬ê³„ìˆ˜ì™€ ì‹¤ì œ ê°’ ê°„ì˜ ì°¨ì´
- **Huber Loss ì‚¬ìš©**: ì´ˆê¸° í° ì˜¤ì°¨ì— ëŒ€í•´ ë” ì•ˆì •ì ì¸ í•™ìŠµ
- **í‰ê· **: 4ê°œ ê³„ìˆ˜ì˜ ê· í˜•ì¡íŒ í•™ìŠµì„ ìœ„í•´ í‰ê·  ì‚¬ìš©

#### 4. **ë¶„ë¥˜ ì†ì‹¤** (Classification Loss)
- **ê³„ì‚°**:
  ```python
  classification_loss = CrossEntropy(class_logits, material_label)
  ```
- **ì˜ë¯¸**: ì¬ë£Œ ë¶„ë¥˜ ì •í™•ë„ (ETF Classifier ì‚¬ìš©)
- **ê°€ì¤‘ì¹˜**: ê¸°ë³¸ê°’ 10.0 (ì£¼ ëª©í‘œ)

#### 5. **ìµœì¢… PINN ì†ì‹¤**
- **ê³„ì‚°**:
  ```python
  total_loss = classification_weight * classification_loss + 
               data_weight * data_loss + 
               physics_weight * physics_loss
  ```
- **ì˜ë¯¸**: ë¶„ë¥˜, ë°ì´í„° ì í•©ë„, ë¬¼ë¦¬ ë²•ì¹™ ë§Œì¡±ë„ë¥¼ ê· í˜•ìˆê²Œ ê²°í•©
- **êµ¬í˜„**: `pde_physics.py`ì˜ `PINNPhysicsLoss` í´ë˜ìŠ¤

## ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì¡°

### ì¬ë£Œ ë° êµ´ì ˆë¥ 
- **ê³µê¸°**: 1.0
- **ë¬¼**: 1.33
- **ì•„í¬ë¦´**: 1.49
- **ìœ ë¦¬**: 1.52
- **ì‚¬íŒŒì´ì–´**: 1.77

### ë°ì´í„° êµ¬ì„±
```
train/
â”œâ”€â”€ air_4D/images/          # 100ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ water_4D/images/         # 100ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ acrylic_4D/images/       # 100ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ glass_4D/images/         # 100ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ sapphire_4D/images/      # 100ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â””â”€â”€ dataset_labels.json      # ì¬ë£Œ ë¼ë²¨ ë° êµ´ì ˆë¥ 

test/
â”œâ”€â”€ air_4D_test/images/      # 50ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ water_4D_test/images/    # 50ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ acrylic_4D_test/images/  # 50ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ glass_4D_test/images/    # 50ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”œâ”€â”€ sapphire_4D_test/images/ # 50ê°œ ìƒ˜í”Œ Ã— 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â””â”€â”€ dataset_labels_test.json # í…ŒìŠ¤íŠ¸ ë¼ë²¨
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •
```bash
# ì„œë¸Œëª¨ë“ˆê³¼ í•¨ê»˜ ì €ì¥ì†Œ í´ë¡ 
git clone --recursive https://github.com/your-username/PICL.git
cd PICL

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install torch torchvision
pip install einops
pip install causal-conv1d
pip install mamba-ssm
```

### 2. ê¸°ë³¸ ì‚¬ìš©ë²•

#### 2D VMamba ë°±ë³¸ ì‚¬ìš©
```python
from vmamba_backbone import VMambaBackbone

# ë°±ë³¸ ì´ˆê¸°í™”
backbone = VMambaBackbone(
    model_name='vmamba_base_s2l15',
    out_indices=(3,),
    channel_first=True
)

# 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬
images = torch.randn(2, 5, 3, 224, 224)  # (B, T, C, H, W)
features = backbone(images)  # (B, 5, 1024)
```

#### ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì„ ìœ„í•œ 1D Mamba ì‚¬ìš©
```python
from mamba_1d_temporal import Mamba1D, SequenceToValue

# 1D Mamba (ê³µì‹ êµ¬í˜„)
mamba1d = Mamba1D(d_model=1024, layer_idx=0, device='cuda')
sequence = torch.randn(2, 5, 1024)  # (B, T, D)
processed = mamba1d(sequence)  # (B, 5, 1024) - ëª¨ë“  íƒ€ì„ìŠ¤í… ì¶œë ¥

# ì‹œí€€ìŠ¤-íˆ¬-ë°¸ë¥˜ ë³€í™˜
seq2val = SequenceToValue(input_dim=1024, device='cuda')
features = torch.randn(2, 5, 1024)  # 2D VMamba + Spatial Projectionì—ì„œ
temporal_features_all = seq2val(features)  # (B, 5, 1024)
temporal_features = temporal_features_all[:, -1, :]  # (B, 1024) - ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…
```

#### ì™„ì „í•œ PICL íŒŒì´í”„ë¼ì¸ (ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡ + PINN ì†ì‹¤)
```python
from picl_model import PICLModel
import torch

# ëª¨ë¸ ì´ˆê¸°í™”
model = PICLModel(
    backbone_model='vmamba_base_s2l15',
    pretrained_path='./vssm_base_0229_ckpt_epoch_237.pth',
    temporal_config={
        'input_dim': 1024,
        'device': 'cuda'
    },
    physics_config={
        'physics_weight': 1.0,  # ë¬¼ë¦¬ ì†ì‹¤ ê°€ì¤‘ì¹˜
        'data_weight': 1.0,     # ë°ì´í„° ì†ì‹¤ ê°€ì¤‘ì¹˜
        'c': 3e8                # ì§„ê³µì—ì„œì˜ ê´‘ì†
    }
)

# ì…ë ¥ ë°ì´í„°
images = torch.randn(2, 5, 3, 224, 224)  # 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
n_true = torch.tensor([1.33, 1.52])      # ì‹¤ì œ êµ´ì ˆë¥  (ë¬¼, ìœ ë¦¬)

# Forward pass (í›ˆë ¨ìš© - ì†ì‹¤ í¬í•¨)
results = model(images, n_true)

# ê²°ê³¼ í™•ì¸
print(f"ì˜ˆì¸¡ëœ êµ´ì ˆë¥ : {results['n_pred']}")
print(f"ì˜ˆì¸¡ëœ í¡ìˆ˜ ê³„ìˆ˜: {results['mu_a_pred']}")
print(f"ì˜ˆì¸¡ëœ ì‚°ë€ ê³„ìˆ˜: {results['mu_s_pred']}")
print(f"ì˜ˆì¸¡ëœ ë¹„ë“±ë°©ì„± ì¸ì: {results['g_pred']}")
print(f"ìœ ë„ëœ ë“±ë°© í™˜ì‚° ì‚°ë€ ê³„ìˆ˜: {results['mu_s_prime_pred']}")
print(f"ì´ ì†ì‹¤: {results['total_loss']}")
print(f"ë°ì´í„° ì†ì‹¤: {results['data_loss']}")
print(f"ë¬¼ë¦¬ ì†ì‹¤: {results['physics_loss']}")

# ì˜ˆì¸¡ë§Œ (ì¶”ë¡ ìš© - ì†ì‹¤ ê³„ì‚° ì—†ìŒ)
n_pred, mu_a_pred, mu_s_prime_pred = model.predict_coefficients(images)
# ë˜ëŠ” ì¬ë£Œ ë¶„ë¥˜ + ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡
results = model.predict_material(images)  # 4ê°œ ê³„ìˆ˜ + ë¶„ë¥˜ ê²°ê³¼
```

### 3. í›ˆë ¨ ë° ì¶”ë¡ 

#### í›ˆë ¨ ì‹¤í–‰
```bash
# ê¸°ë³¸ ì‹¤í–‰
python train_picl.py config_picl.py --work-dir work_dirs/picl_vmamba_base --device cuda

# ë˜ëŠ” run_picl.sh ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (í›ˆë ¨ + ì¶”ë¡  ìë™ ì‹¤í–‰)
bash run_picl.sh
```

#### í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ê¸°ëŠ¥
- **ë°ì´í„° ë¡œë”**: JSON íŒŒì¼ ê¸°ë°˜ ë°ì´í„°ì…‹ ìë™ ë¡œë“œ
- **ì²´í¬í¬ì¸íŠ¸ ì €ì¥**:
  - `best.pth`: ìµœê³  ì •í™•ë„ ëª¨ë¸ (ê°±ì‹  ì‹œ ì €ì¥)
  - `latest.pth`: ë§¤ epochë§ˆë‹¤ ì €ì¥
  - `last.pth`: ë§ˆì§€ë§‰ epoch ëª¨ë¸
- **ì†ì‹¤ í‘œì‹œ**: ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§„ loss ê°’ í‘œì‹œ (ì§„í–‰ë°” ë° epoch ìš”ì•½)
- **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬**: ReduceLROnPlateau, CosineAnnealingLR, StepLR, MultiStepLR ì§€ì›

#### ì¶”ë¡  ì‹¤í–‰
```bash
# ë°ì´í„°ì…‹ ì „ì²´ì— ëŒ€í•´ ì¶”ë¡ 
python inference_picl.py config_picl.py work_dirs/picl_vmamba_base/best.pth \
    --mode dataset \
    --output-dir work_dirs/picl_vmamba_base/inference_results \
    --device cuda

# ë‹¨ì¼ ìƒ˜í”Œ ì¶”ë¡ 
python inference_picl.py config_picl.py work_dirs/picl_vmamba_base/best.pth \
    --mode single \
    --images img1.png img2.png img3.png img4.png img5.png \
    --output-dir ./output \
    --device cuda
```

#### ì¶”ë¡  ê²°ê³¼
- ì¬ë£Œ ë¶„ë¥˜ ì •í™•ë„ ë° í˜¼ë™ í–‰ë ¬
- êµ´ì ˆë¥  ì˜ˆì¸¡ í†µê³„ (MSE, MAE)
- ì¬ë£Œë³„ ìƒì„¸ í†µê³„
- JSON í˜•ì‹ ê²°ê³¼ ì €ì¥

## ğŸ”¬ ì—°êµ¬ ë§¥ë½

### ë¬¼ë¦¬ ì •ë³´ ê¸°ë°˜ ì‹ ê²½ë§ (PINN)
- **ê´€ì¸¡ ë°ì´í„°ì™€ ë¬¼ë¦¬ ë²•ì¹™ í†µí•©**: ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ ì‚¬ìš©
  ```
  n/c * âˆ‚Î¦/âˆ‚t + Î¼a*Î¦ - âˆ‡Â·(Dâˆ‡Î¦) = 0
  ```
- **ì´ì¤‘ ì†ì‹¤ í•¨ìˆ˜**: 
  - ë°ì´í„° ì†ì‹¤: ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µ ë¼ë²¨ ë¹„êµ
  - ë¬¼ë¦¬ ì†ì‹¤: ì˜ˆì¸¡ê°’ì´ ë¬¼ë¦¬ ë°©ì •ì‹ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì¦
- **ìë™ ë¬¼ë¦¬ ë²•ì¹™ ê²€ì¦**: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ì–¼ë§ˆë‚˜ ì˜ ë”°ë¥´ëŠ”ì§€ ìë™ ê³„ì‚°
- **ë¬¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ëœ ì˜ˆì¸¡**: ë¬¼ë¦¬ ì œì•½ ì¡°ê±´ì„ í†µí•´ ë” ì •í™•í•˜ê³  ë¬¼ë¦¬ì ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ì˜ˆì¸¡ ê°€ëŠ¥

### ì—°ì† í•™ìŠµ
- ìˆœì°¨ í•™ìŠµì—ì„œì˜ íŒŒê´´ì  ë§ê° ë¬¸ì œ í•´ê²°
- ì•ˆì •ì„±(ê¸°ì¡´ ì§€ì‹ ìœ ì§€)ê³¼ ê°€ì†Œì„±(ìƒˆë¡œìš´ ì‘ì—… í•™ìŠµ)ì˜ ê· í˜•
- ì‹¤ì œ ê´‘í•™ ì¸¡ì • ì‹œë‚˜ë¦¬ì˜¤ì— í•„ìˆ˜ì 

### ê´‘í•™ ì—­ë¬¸ì œ
- **ìˆœë°©í–¥ ë¬¸ì œ**: êµ´ì ˆë¥  ì£¼ì–´ì§ â†’ ê´‘í•™ ì‚°ë€ ì˜ˆì¸¡
- **ì—­ë°©í–¥ ë¬¸ì œ**: ê´‘í•™ ì‚°ë€ ì£¼ì–´ì§ â†’ êµ´ì ˆë¥  ì¶”ì •
- **ë„ì „ê³¼ì œ**: ë¹„ì„ í˜•, ë¶€ì ì ˆí•œ ë¬¸ì œ, ì‹œê°„ì  ë™ì—­í•™ ëª¨ë¸ë§ í•„ìš”

### ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ (Time-dependent Diffusion Equation)

PICL í”„ë ˆì„ì›Œí¬ì—ì„œ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ë¬¼ë¦¬ ë°©ì •ì‹:

```
n/c * âˆ‚Î¦/âˆ‚t + Î¼a*Î¦ - âˆ‡Â·(Dâˆ‡Î¦) = S(r,t) â‰ˆ 0
```

#### ë°©ì •ì‹ì˜ ë¬¼ë¦¬ì  ì˜ë¯¸
- **n/c * âˆ‚Î¦/âˆ‚t**: í”Œë£¨ì–¸ìŠ¤ìœ¨ì˜ ì‹œê°„ ë³€í™” (êµ´ì ˆë¥ ì— ì˜í•œ ë¹›ì˜ ì†ë„ ì¡°ì ˆ)
- **Î¼a*Î¦**: ë§¤ì§ˆì— ì˜í•œ ë¹›ì˜ í¡ìˆ˜
- **-âˆ‡Â·(Dâˆ‡Î¦)**: ë§¤ì§ˆ ë‚´ì—ì„œì˜ ë¹›ì˜ í™•ì‚° (í™•ì‚° ê³„ìˆ˜ Dì— ì˜í•´ ê²°ì •)
- **S(r,t)**: ê´‘ì› í•­ (ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ëŠ” ê´‘ì›ì´ êº¼ì§„ í›„ ìƒíƒœì´ë¯€ë¡œ â‰ˆ 0)

#### ê° ë¬¼ë¦¬ê³„ìˆ˜ì˜ ì—­í• 
- **n (êµ´ì ˆë¥ )**: ë¹›ì˜ ì†ë„ë¥¼ ì¡°ì ˆ (`c/n` = ë§¤ì§ˆ ë‚´ ë¹›ì˜ ì†ë„)
- **Î¼a (í¡ìˆ˜ ê³„ìˆ˜)**: ë¹›ì´ ì–¼ë§ˆë‚˜ í¡ìˆ˜ë˜ëŠ”ì§€ ê²°ì •
- **Î¼s (ì‚°ë€ ê³„ìˆ˜)**: ë¹›ì´ ì–¼ë§ˆë‚˜ ì‚°ë€ë˜ëŠ”ì§€ ê²°ì • (ì´ ì‚°ë€)
- **g (ë¹„ë“±ë°©ì„± ì¸ì)**: ì‚°ë€ì˜ ë°©í–¥ì„± (0: ë“±ë°©ì„±, 1: ì „ë°© ì‚°ë€)
- **Î¼s' (ë“±ë°© í™˜ì‚° ì‚°ë€ ê³„ìˆ˜)**: Î¼s Ã— (1 - g)ë¡œ ê³„ì‚° (ìœ íš¨ ì‚°ë€)
- **D (í™•ì‚° ê³„ìˆ˜)**: D = 1/(3*(Î¼a + Î¼s'))ë¡œ ê³„ì‚°

#### PINNì—ì„œì˜ í™œìš©
- ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ (`n_pred`, `Î¼a_pred`, `Î¼s_pred`, `g_pred`)ë¡œë¶€í„° `Î¼s'_pred = Î¼s_pred Ã— (1 - g_pred)` ê³„ì‚°
- ì˜ˆì¸¡ëœ ê³„ìˆ˜ë¥¼ ë°©ì •ì‹ì— ëŒ€ì…
- ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ê³„ì‚°ëœ ë¬¼ë¦¬ëŸ‰ (`Î¦`, `âˆ‚Î¦/âˆ‚t`, `âˆ‡Â²Î¦`)ì„ ë°©ì •ì‹ì— ëŒ€ì…
- ì”ì°¨(residual)ë¥¼ ê³„ì‚°í•˜ì—¬ ë¬¼ë¦¬ ë²•ì¹™ ë§Œì¡± ì—¬ë¶€ ê²€ì¦
- 4ê°œ ê¸°ë³¸ ê³„ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ë¬¼ë¦¬ì  ê´€ê³„ (Î¼s' = Î¼s(1-g)) ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ë§

## ğŸ“ ì €ì¥ì†Œ êµ¬ì¡°

```
PICL/
â”œâ”€â”€ FSCIL/                          # ì„œë¸Œëª¨ë“ˆ: FSCIL ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ mmfscil/models/
â”‚   â”‚   â””â”€â”€ vmamba_backbone.py      # ì›ë³¸ VMamba êµ¬í˜„
â”‚   â””â”€â”€ VMamba/                     # VMamba ì†ŒìŠ¤ ì½”ë“œ
â”œâ”€â”€ mamba/                          # ì„œë¸Œëª¨ë“ˆ: ê³µì‹ Mamba ì €ì¥ì†Œ
â”‚   â””â”€â”€ mamba_ssm/                  # Mamba ì†ŒìŠ¤ ì½”ë“œ
â”œâ”€â”€ vmamba_backbone.py              # 2D VMamba ë°±ë³¸
â”‚   â””â”€â”€ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì§€ì›
â”‚   â””â”€â”€ ê³µê°„ íŠ¹ì§• ì¶”ì¶œ (PATH 1ì—ì„œ ì‚¬ìš©)
â”œâ”€â”€ mamba_1d_temporal.py            # 1D Mamba + SequenceToValue
â”‚   â””â”€â”€ Mamba1D: ê³µì‹ 1D Mamba êµ¬í˜„
â”‚   â””â”€â”€ SequenceToValue: ì‹œí€€ìŠ¤ë¥¼ ë‹¨ì¼ ë²¡í„°ë¡œ ë³€í™˜ (PATH 1ì—ì„œ ì‚¬ìš©)
â”œâ”€â”€ pde_physics.py                  # ë¬¼ë¦¬ ë°©ì •ì‹ ë° PINN ì†ì‹¤
â”‚   â””â”€â”€ TimeDependentDiffusionPDE: ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ êµ¬í˜„
â”‚   â””â”€â”€ PINNPhysicsLoss: ë°ì´í„° ì†ì‹¤ + ë¬¼ë¦¬ ì†ì‹¤ í†µí•©
â”‚   â””â”€â”€ ë¬¼ë¦¬ëŸ‰ ê³„ì‚° í•¨ìˆ˜ë“¤ (ì‹œê°„ ë¯¸ë¶„, ê³µê°„ ë¯¸ë¶„ ë“±)
â”œâ”€â”€ picl_model.py                   # ì™„ì „í•œ PICL í†µí•© ëª¨ë¸
â”‚   â””â”€â”€ PICLModel: PATH 1 + PATH 2 í†µí•© í´ë˜ìŠ¤
â”‚   â””â”€â”€ FTTransformerRegressor: ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡ í—¤ë“œ (Transformer ê¸°ë°˜)
â”‚   â””â”€â”€ ETFClassifier: ì¬ë£Œ ë¶„ë¥˜ í—¤ë“œ
â”‚   â””â”€â”€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰
â”œâ”€â”€ train_picl.py                   # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ ë°ì´í„° ë¡œë”, í›ˆë ¨ ë£¨í”„, ì²´í¬í¬ì¸íŠ¸ ì €ì¥
â”œâ”€â”€ inference_picl.py               # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ ë°ì´í„°ì…‹/ë‹¨ì¼ ìƒ˜í”Œ ì¶”ë¡ , í†µê³„ ê³„ì‚°
â”œâ”€â”€ config_picl.py                  # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ ëª¨ë¸, ë°ì´í„°, í›ˆë ¨ ì„¤ì •
â”œâ”€â”€ run_picl.sh                     # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ í›ˆë ¨ + ì¶”ë¡  ìë™ ì‹¤í–‰
â”œâ”€â”€ train/                          # í›ˆë ¨ ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ air_4D/images/             # 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ water_4D/images/
â”‚   â”œâ”€â”€ acrylic_4D/images/
â”‚   â”œâ”€â”€ glass_4D/images/
â”‚   â”œâ”€â”€ sapphire_4D/images/
â”‚   â””â”€â”€ dataset_labels.json         # ì¬ë£Œ ë¼ë²¨ ë° êµ´ì ˆë¥ 
â”œâ”€â”€ test/                           # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
â”‚   â””â”€â”€ ... (ë™ì¼í•œ êµ¬ì¡°)
â””â”€â”€ README.md                       # ì´ íŒŒì¼
```

## ğŸ§ª ì£¼ìš” íŠ¹ì§•

### 1. **ì´ì¤‘ ê²½ë¡œ ì•„í‚¤í…ì²˜ (Dual-Path Architecture)**
- **PATH 1 (ì‹ ê²½ë§)**: 2D VMamba â†’ Spatial Projection â†’ 1D Mamba (ë§ˆì§€ë§‰ timestep) â†’ FT-Transformer â†’ 4ê°œ ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡
- **PATH 2 (ë¬¼ë¦¬)**: ì›ë³¸ ì´ë¯¸ì§€ â†’ ë¬¼ë¦¬ëŸ‰ ê³„ì‚° â†’ PDE ê²€ì¦
- **ë™ì‹œ ì‹¤í–‰**: ë‘ ê²½ë¡œê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ì–´ íš¨ìœ¨ì„± ê·¹ëŒ€í™”

### 2. **ì‹œê°„ ê²Œì´íŠ¸ ì²˜ë¦¬**
- 5ì¥ì˜ ì—°ì†ëœ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬ (0-1ns ~ 4-5ns)
- ì‹œê°„ì  ì‹œí€€ìŠ¤ ì •ë³´ ì™„ì „ ë³´ì¡´
- ë¬¼ë¦¬ ì •ë³´ ê¸°ë°˜ ì‹œê°„ì  ëª¨ë¸ë§ ê°€ëŠ¥

### 3. **ë¬¼ë¦¬ ì •ë³´ ê¸°ë°˜ ì‹ ê²½ë§ (PINN)**
- **ë¬¼ë¦¬ ë°©ì •ì‹**: ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ í†µí•©
  ```
  n/c * âˆ‚Î¦/âˆ‚t + Î¼a*Î¦ - âˆ‡Â·(Dâˆ‡Î¦) = 0
  ```
- **ì´ì¤‘ ì†ì‹¤ í•¨ìˆ˜**: ë°ì´í„° ì†ì‹¤ + ë¬¼ë¦¬ ì†ì‹¤
- **ë¬¼ë¦¬ ë²•ì¹™ ê²€ì¦**: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ë§Œì¡±í•˜ëŠ”ì§€ ìë™ ê²€ì¦

### 4. **ê³µì‹ Mamba êµ¬í˜„**
- state-spaces/mamba ê³µì‹ êµ¬í˜„ ì‚¬ìš©
- 1D Mamba: ì‹œê°„ì  ì‹œí€€ìŠ¤ ëª¨ë¸ë§
- ê¸´ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì„ í˜• ë³µì¡ë„
- Transformer ëŒ€ë¹„ ìš°ìˆ˜í•œ ì„±ëŠ¥

### 5. **ë¬¼ë¦¬ëŸ‰ ê³„ì‚° (ìœ í•œ ì°¨ë¶„ë²•)**
- **ì‹œê°„ ë¯¸ë¶„**: Forward Differenceë¡œ âˆ‚Î¦/âˆ‚t ê³„ì‚°
- **ê³µê°„ ë¯¸ë¶„**: Central Differenceë¡œ âˆ‡Â²Î¦ ê³„ì‚°
- **íš¨ìœ¨ì  ê³„ì‚°**: GPU ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì „ì²´ ì´ë¯¸ì§€ ë™ì‹œ ê³„ì‚°

### 6. **ëª¨ë“ˆí™” ì„¤ê³„**
- 2D VMamba: ê³µê°„ íŠ¹ì§• ì¶”ì¶œ (`vmamba_backbone.py`)
- 1D Mamba: ì‹œê°„ì  ì‹œí€€ìŠ¤ ëª¨ë¸ë§ (`mamba_1d_temporal.py`)
- ë¬¼ë¦¬ ë°©ì •ì‹: PDE ê³„ì‚° ë° ê²€ì¦ (`pde_physics.py`)
- í†µí•© ëª¨ë¸: ì „ì²´ íŒŒì´í”„ë¼ì¸ (`picl_model.py`)
- í™•ì¥ ë° ìˆ˜ì • ìš©ì´

## ğŸ“ˆ ì„±ëŠ¥

- **ë°ì´í„°ì…‹**: 5ê°œ ì¬ë£Œ Ã— 100ê°œ í›ˆë ¨ ìƒ˜í”Œ Ã— 50ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ
- **ì…ë ¥**: ìƒ˜í”Œë‹¹ 5ì¥ì˜ ì‹œê°„ ê²Œì´íŠ¸ ì´ë¯¸ì§€ (224Ã—224Ã—3)
- **ì¶œë ¥**: ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡
  - êµ´ì ˆë¥  (n): 1.0 ~ 1.77
  - í¡ìˆ˜ ê³„ìˆ˜ (Î¼a): 0.01 ~ 0.1 mmâ»Â¹
  - ì‚°ë€ ê³„ìˆ˜ (Î¼s): 0.5 ~ 50.0 mmâ»Â¹
  - ë¹„ë“±ë°©ì„± ì¸ì (g): 0.89 ~ 0.95
  - ë“±ë°© í™˜ì‚° ì‚°ë€ ê³„ìˆ˜ (Î¼s'): Î¼s Ã— (1 - g)ë¡œ ê³„ì‚°
- **ì•„í‚¤í…ì²˜**: VMamba + Spatial Projection + 1D Mamba (ë§ˆì§€ë§‰ timestep) + FT-Transformer + ETF Classifier + PINN ì†ì‹¤
- **ì†ì‹¤ í•¨ìˆ˜**: 
  - Classification Loss (CrossEntropy) - ê°€ì¤‘ì¹˜: 10.0
  - Data Loss (Huber Loss, delta=0.1) - ê°€ì¤‘ì¹˜: 1.0
    - 4ê°œ ê³„ìˆ˜ (n, Î¼a, Î¼s, g) ê°ê°ì— ëŒ€í•´ ê³„ì‚° í›„ í‰ê· 
  - Physics Loss (Huber Loss, delta=0.1) - ê°€ì¤‘ì¹˜: 0.01
- **ë¬¼ë¦¬ ë‹¨ìœ„**: 
  - ê³µê°„: `dx=dy=1e-3 m` (1.0 mm)
  - ì‹œê°„: `dt=1e-9 s` (1.0 ns)

## âœ… êµ¬í˜„ ìƒíƒœ

### ì™„ë£Œëœ êµ¬í˜„

#### í•µì‹¬ ëª¨ë“ˆ
- âœ… **vmamba_backbone.py**: 2D VMamba ë°±ë³¸ (ì‹œê°„ ê²Œì´íŠ¸ ì²˜ë¦¬ ì§€ì›)
- âœ… **mamba_1d_temporal.py**: 1D Mamba + SequenceToValue êµ¬í˜„
- âœ… **pde_physics.py**: 
  - âœ… ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ êµ¬í˜„
  - âœ… ë¬¼ë¦¬ëŸ‰ ê³„ì‚° í•¨ìˆ˜ (ì‹œê°„ ë¯¸ë¶„, ê³µê°„ ë¯¸ë¶„)
  - âœ… PDE ì”ì°¨ ê³„ì‚°
  - âœ… PINN ì†ì‹¤ í•¨ìˆ˜ (ë°ì´í„° ì†ì‹¤ + ë¬¼ë¦¬ ì†ì‹¤)
- âœ… **picl_model.py**: 
  - âœ… ì™„ì „í•œ PICL í†µí•© ëª¨ë¸
  - âœ… PATH 1 (ì‹ ê²½ë§ ì˜ˆì¸¡) + PATH 2 (ë¬¼ë¦¬ëŸ‰ ê³„ì‚°) í†µí•©
  - âœ… ë™ì‹œ ì‹¤í–‰ ë° ìë™ ì†ì‹¤ ê³„ì‚°

#### ê¸°ëŠ¥
- âœ… 4ê°€ì§€ ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡ (n, Î¼a, Î¼s, g) + Î¼s' ìœ ë„
- âœ… ì¬ë£Œ ë¶„ë¥˜ (ETF Classifier)
- âœ… ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë¬¼ë¦¬ëŸ‰ ê³„ì‚°
- âœ… PDE ë°©ì •ì‹ ê²€ì¦
- âœ… ë¬¼ë¦¬ ì†ì‹¤ ìë™ ê³„ì‚°
- âœ… Huber Loss ì ìš© (ë°ì´í„° ë° ë¬¼ë¦¬ ì†ì‹¤)
- âœ… ë¬¼ë¦¬ ë‹¨ìœ„ í†µí•© (dx, dy, dt)
- âœ… ëª¨ë“  ì‹œê°„ ìŠ¤í…ì—ì„œ ê³µê°„ ë¯¸ë¶„ ê³„ì‚°
- âœ… Spatial Projectionìœ¼ë¡œ ê³µê°„-ì‹œê°„ ì²˜ë¦¬ ê°œì„ 
- âœ… FT-Transformerë¡œ ë¬¼ë¦¬ ê³„ìˆ˜ ê°„ ìƒê´€ê´€ê³„ í•™ìŠµ

#### í›ˆë ¨ ë° ì¶”ë¡  ë„êµ¬
- âœ… **train_picl.py**: ì™„ì „í•œ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
  - ë°ì´í„° ë¡œë” (JSON ê¸°ë°˜)
  - ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (best, latest, last)
  - ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§„ loss í‘œì‹œ
  - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì§€ì›
- âœ… **inference_picl.py**: ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
  - ë°ì´í„°ì…‹ ì „ì²´ ì¶”ë¡ 
  - ë‹¨ì¼ ìƒ˜í”Œ ì¶”ë¡ 
  - ìƒì„¸ í†µê³„ ë° ê²°ê³¼ ì €ì¥
- âœ… **run_picl.sh**: í›ˆë ¨ + ì¶”ë¡  ìë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

## ğŸ”® í–¥í›„ ì—°êµ¬

1. âœ… **ë¬¼ë¦¬ ì†ì‹¤ í†µí•©**: ì‹œê°„ ì˜ì¡´ í™•ì‚° ë°©ì •ì‹ ì™„ë£Œ
2. âœ… **ê³µê°„ ë¯¸ë¶„ ê°œì„ **: ëª¨ë“  ì‹œê°„ ìŠ¤í…ì— ëŒ€í•´ ê³µê°„ ë¯¸ë¶„ ê³„ì‚° ì™„ë£Œ
3. âœ… **Huber Loss ì ìš©**: ë°ì´í„° ë° ë¬¼ë¦¬ ì†ì‹¤ì— Huber Loss ì ìš© ì™„ë£Œ
4. âœ… **ë¬¼ë¦¬ ë‹¨ìœ„ í†µí•©**: ì‹¤ì œ ë¬¼ë¦¬ ë‹¨ìœ„ (mm, ns) ì ìš© ì™„ë£Œ
5. **ì—°ì† í•™ìŠµ**: ìˆœì°¨ì  ì¬ë£Œ í•™ìŠµì„ ìœ„í•œ FSCIL êµ¬í˜„
6. **Source Term ëª¨ë¸ë§**: ê´‘ì› í•­(S)ì„ ë™ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê±°ë‚˜ ë” ì •í™•íˆ ëª¨ë¸ë§
7. **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ì‹¤ì œ ì‘ìš©ì„ ìœ„í•œ ìµœì í™”
8. **ë‹¤ì¤‘ ë¬¼ë¦¬ ë°©ì •ì‹**: ë‹¤ë¥¸ ë¬¼ë¦¬ ë²•ì¹™ ì¶”ê°€ í†µí•©

## ğŸ”‘ í•µì‹¬ ê°œë… ì •ë¦¬

### 1. ì™œ ë‘ ê²½ë¡œê°€ ë¶„ë¦¬ë˜ì–´ ìˆë‚˜?

**PATH 1 (ì‹ ê²½ë§)**: ë¬¼ë¦¬ê³„ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  í•™ìŠµ
- VMambaë¡œ ê³µê°„ íŠ¹ì§• ì¶”ì¶œ â†’ 1D Mambaë¡œ ì‹œê°„ ì²˜ë¦¬ â†’ MLPë¡œ ì˜ˆì¸¡
- ëª©ì : ì´ë¯¸ì§€ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ë¬¼ë¦¬ê³„ìˆ˜ ì˜ˆì¸¡

**PATH 2 (ë¬¼ë¦¬)**: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì¦
- ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë¬¼ë¦¬ëŸ‰ ì§ì ‘ ê³„ì‚° â†’ PDE ë°©ì •ì‹ ê²€ì¦
- ëª©ì : ë¬¼ë¦¬ ë²•ì¹™ ìœ„ë°˜ì„ ê°ì§€í•˜ê³  ìˆ˜ì •

**ê²°í•©**: PATH 1ì˜ ì˜ˆì¸¡ê°’ê³¼ PATH 2ì˜ ê³„ì‚°ê°’ì„ PDE ë°©ì •ì‹ì—ì„œ ê²°í•©í•˜ì—¬ ë¬¼ë¦¬ ì†ì‹¤ ê³„ì‚°

### 2. ì™œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë‚˜?

- ë¬¼ë¦¬ëŸ‰(`Î¦`, `âˆ‚Î¦/âˆ‚t`, `âˆ‡Â²Î¦`)ì€ MCX ì‹œë®¬ë ˆì´ì…˜ì˜ ì§ì ‘ì ì¸ ê²°ê³¼ë¬¼
- ê³µê°„ ë¯¸ë¶„ ê³„ì‚°ì—ëŠ” ì›ë³¸ ì´ë¯¸ì§€ì˜ ê³µê°„ ì •ë³´ê°€ í•„ìš”
- VMambaë¥¼ ê±°ì¹œ íŠ¹ì§•ë§µì€ ì¶”ìƒí™”ë˜ì–´ ë¬¼ë¦¬ëŸ‰ ê³„ì‚°ì— ë¶€ì í•©
- PINNì˜ í‘œì¤€ ê´€í–‰: ê´€ì¸¡ ë°ì´í„°(ì›ë³¸ ì´ë¯¸ì§€)ë¥¼ ì§ì ‘ ì‚¬ìš©

### 3. Residualì´ 4ê°œì¸ ì´ìœ 

- 5ì¥ì˜ ì´ë¯¸ì§€ â†’ 4ê°œì˜ ì‹œê°„ ê°„ê²© (t1-t2, t2-t3, t3-t4, t4-t5)
- ê° ì‹œê°„ ê°„ê²©ë§ˆë‹¤ í•˜ë‚˜ì˜ residual ê³„ì‚°
- ìµœì¢… ì†ì‹¤: ëª¨ë“  residualì˜ í‰ê·  (`mean(residual^2)`)

### 4. ê³µê°„ ì°¨ì›ì„ ìœ ì§€í•˜ëŠ” ì´ìœ 

- ë¬¼ë¦¬ ë°©ì •ì‹ì—ì„œ `Î¦(r,t)`ëŠ” ìœ„ì¹˜ `r`ì— ë”°ë¼ ë³€í•˜ëŠ” í•¨ìˆ˜
- ê° í”½ì…€(ìœ„ì¹˜)ë§ˆë‹¤ ë¬¼ë¦¬ ë²•ì¹™ì„ ê²€ì¦í•´ì•¼ í•¨
- ê³µê°„ ë¯¸ë¶„(`âˆ‡Â²Î¦`) ê³„ì‚°ì´ ê³µê°„ ì°¨ì› í•„ìš”
- ìµœì¢… ì†ì‹¤ì€ ëª¨ë“  í”½ì…€ì˜ ì”ì°¨ë¥¼ í‰ê· ë‚´ì–´ ê³„ì‚°

### 5. ë¬¼ë¦¬ ì†ì‹¤ì˜ ì˜ë¯¸

- `physics_loss â‰ˆ 0`: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ì˜ ë§Œì¡± â†’ ì¢‹ì€ ì˜ˆì¸¡
- `physics_loss > 0`: ì˜ˆì¸¡ëœ ë¬¼ë¦¬ê³„ìˆ˜ê°€ ë¬¼ë¦¬ ë²•ì¹™ì„ ìœ„ë°˜ â†’ ë‚˜ìœ ì˜ˆì¸¡
- ë¬¼ë¦¬ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ â†’ ë¬¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ëœ ì˜ˆì¸¡ ê°€ëŠ¥

## ğŸ“š ì°¸ê³ ë¬¸í—Œ

- [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752)
- [VMamba: Visual State Space Model](https://arxiv.org/abs/2401.10166)
- [FSCIL: Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2004.10956)
- [Physics-Informed Neural Networks](https://arxiv.org/abs/1711.10561)